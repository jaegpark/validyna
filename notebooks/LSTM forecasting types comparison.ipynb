{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dysts.flows\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from dysts.base import DynSys\n",
    "from numpy.random import rand\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "\n",
    "from config import ROOT_DIR\n",
    "from ecodyna.data import build_in_out_pair_dataset, load_or_generate_and_save, build_data_path\n",
    "from ecodyna.metrics import ForecastMetricLogger\n",
    "from ecodyna.models.mutitask_models import MyGRU, MyLSTM\n",
    "from ecodyna.models.task_modules import ChunkForecaster\n",
    "from ecodyna.plot import plot_1d_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "{'data': {'attractor': 'Lorenz',\n  'trajectory_count': 100,\n  'trajectory_length': 1000,\n  'resample': True,\n  'pts_per_period': 0.01,\n  'ic_noise': 0.01},\n 'experiment': {'max_epochs': 50, 'train_part': 0.75, 'random_seed': 26},\n 'in_out': {'n_in': 10, 'n_out': 5},\n 'models': {'n_hidden': 32, 'n_layers': 1, 'n_in': 10, 'n_out': 5},\n 'dataloader': {'batch_size': 64, 'num_workers': 8, 'n_in': 10, 'n_out': 5}}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'data': {\n",
    "        'attractor': 'Lorenz',\n",
    "        'trajectory_count': 100,\n",
    "        'trajectory_length': 1000,\n",
    "        'resample': True,\n",
    "        'pts_per_period': 50,\n",
    "        'ic_noise': 0.01\n",
    "    },\n",
    "    'experiment': {\n",
    "        'max_epochs': 50,\n",
    "        'train_part': 0.75,\n",
    "        'random_seed': 26\n",
    "    },\n",
    "    'in_out': {\n",
    "        'n_in': 10,\n",
    "        'n_out': 5\n",
    "    },\n",
    "    'models': {\n",
    "        'n_hidden': 32,\n",
    "        'n_layers': 1\n",
    "    },\n",
    "    'dataloader': {\n",
    "        'batch_size': 64,\n",
    "        'num_workers': 8\n",
    "    }\n",
    "}\n",
    "params['models']['common'].update(params['in_out'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 26\n"
     ]
    }
   ],
   "source": [
    "# Sets random seed for random, numpy and torch\n",
    "pl.seed_everything(params['experiment']['random_seed'], workers=True);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for attractor Lorenz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "attractor: DynSys = getattr(dysts.flows, params['data']['attractor'])()\n",
    "\n",
    "attractor_x0 = attractor.ic.copy()\n",
    "space_dim = len(attractor_x0)\n",
    "\n",
    "data = load_or_generate_and_save(path=build_data_path(**params['data']),\n",
    "                                 attractor=attractor, verbose=True, **params['data'],\n",
    "                                 ic_fun=lambda: params['data']['ic_noise'] * (rand(space_dim) - 0.5) + attractor_x0)\n",
    "\n",
    "train_size = int(params['experiment']['train_part'] * params['data']['trajectory_count'])\n",
    "val_size = params['data']['trajectory_count'] - train_size\n",
    "\n",
    "dataset = TensorDataset(data)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_data = data[train_dataset.indices]\n",
    "val_data = data[val_dataset.indices]\n",
    "\n",
    "chunk_train_dataset = build_in_out_pair_dataset(train_dataset, **params['in_out'])\n",
    "chunk_val_dataset = build_in_out_pair_dataset(val_dataset, **params['in_out'])\n",
    "\n",
    "chunk_train_dl = DataLoader(chunk_train_dataset, **params['dataloader'], shuffle=True)\n",
    "chunk_val_dl = DataLoader(chunk_val_dataset, **params['dataloader'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, **params['dataloader'])\n",
    "val_dataloader = DataLoader(val_dataset, **params['dataloader'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train_rnn_and_plot_forecasts(rnn):\n",
    "    n_plots = 4\n",
    "    forecaster = ChunkForecaster(model=rnn)\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        save_dir=f'{ROOT_DIR}/results',\n",
    "        project='notebook-lstm-forecast-types-chunkyness-evaluation',\n",
    "        name=f\"{rnn.name()}_{params['data']['attractor']}_{rnn.forecast_type}\"\n",
    "    )\n",
    "\n",
    "    wandb_logger.experiment.config.update({\n",
    "        'forecaster': {'name': rnn.name(), **rnn.hyperparams},\n",
    "        'data': params['data'],\n",
    "        'dataloader': params['dataloader'],\n",
    "        'experiment': params['experiment']\n",
    "    })\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=params['experiment']['max_epochs'],\n",
    "        callbacks=[EarlyStopping('val_loss', patience=5), ForecastMetricLogger(train_dataset, val_dataset)],\n",
    "        logger=wandb_logger)\n",
    "\n",
    "    trainer.fit(forecaster, train_dataloaders=chunk_train_dl, val_dataloaders=chunk_val_dl)\n",
    "\n",
    "    for name, data, dataloader in [('train', train_data, train_dataloader), ('validation', val_data, val_dataloader)]:\n",
    "        labels = [f'ground truth ({name})']\n",
    "        tensors = [data]\n",
    "        for func_name, forecast_func in rnn.get_applicable_forecast_functions().items():\n",
    "            forecaster.prediction_func = forecast_func\n",
    "            predictions = torch.concat(trainer.predict(forecaster, dataloaders=dataloader))\n",
    "            labels.append(f'prediction ({func_name})')\n",
    "            tensors.append(predictions)\n",
    "        plot_1d_trajectories(labels=labels, tensors=tensors, n_plots=n_plots)\n",
    "    wandb_logger.experiment.finish(quiet=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_rnn_and_plot_forecasts(\n",
    "    rnn=MyGRU(forecast_type='one_by_one', space_dim=space_dim, **params['models']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_rnn_and_plot_forecasts(\n",
    "    rnn=MyLSTM(forecast_type='one_by_one', space_dim=space_dim, **params['models']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_rnn_and_plot_forecasts(rnn=MyLSTM(forecast_type='multi', space_dim=space_dim, **params['models']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}